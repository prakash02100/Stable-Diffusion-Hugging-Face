{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakash02100/Stable-Diffusion-Hugging-Face/blob/main/stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Hlz5VStwQb"
      },
      "source": [
        "**GENERATIVE AI**<br>\n",
        "\n",
        "\"Stable Diffusion Model: A Comprehensive Guide to Implementation and Error Handling using PyTorch, TensorFlow, and CUDA with an Introduction to Python DALL-E API and Postman\"<br>\n",
        "\n",
        "Github : **prakash72716@gmail.com**<br>\n",
        "Linkedin : https://www.linkedin.com/in/prakash-dass-r-97577725b\n",
        "<br><br>\n",
        "I built this in reference of youtube and Github.<br>\n",
        "Documentation :https://docs.google.com/document/d/1Rw1UpYrDvMyM6yhf-7zlGhJZUfzl5RYUXKogtqOlZ8s/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Z9ddK5JpjY"
      },
      "source": [
        "Start with installing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QuFz5uGi-h6G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 437, in _error_catcher\n",
            "    yield\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
            "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 526, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
            "    data = self.__fp.read(amt)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\http\\client.py\", line 465, in read\n",
            "    s = self.fp.read(amt)\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\ssl.py\", line 1278, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\ssl.py\", line 1134, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TimeoutError: The read operation timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 160, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 400, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 481, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 373, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 204, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
            "    return bool(self._sequence)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
            "    return any(self)\n",
            "           ^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
            "    candidate = func()\n",
            "                ^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n",
            "    super().__init__(\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 491, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 536, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
            "    file = get_http_url(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
            "    for chunk in response.raw.stream(\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 621, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 559, in read\n",
            "    with self._error_catcher():\n",
            "  File \"d:\\python\\Lib\\contextlib.py\", line 155, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"d:\\python\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 442, in _error_catcher\n",
            "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
            "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade diffusers transformers scipy mediapy accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pkEI3oVt_QD"
      },
      "source": [
        "In this block of code it will ask for your token from Hugging Face. \n",
        "\n",
        "If you don't have an account you can make one here: https://huggingface.co/join\n",
        "\n",
        "Before you can do this you need to accept the license agreement for the model, which you can do here: https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
        "\n",
        "On the token page select \"new token\" and ask for a \"read\" token (you can name it anything you want)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PaPTEKMIj3_"
      },
      "source": [
        "To get the token , you need to run this code then a link will available to you then. There you can get new token.\n",
        "<br>\n",
        "DOWN HERE YOU NEED TO ENTER THE TOKEN NUMBER AND THEN GIVE Y.THEN YOU CAN SEE THE MESSAGE \"LOGIN SUCCESFUL\". MOVE ON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GR4vF2bw-sHR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'huggingface-cli' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAA8E3zXuKm1"
      },
      "source": [
        "Now we set up our model and pipeline. IF you want to remove the NSFW safety checker, change \"remove_safety\" to \"True\".<br>\n",
        "**NSFW stands for \"Not Safe for Work\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vF9Q0xKX8gLR"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'diffusers'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler\n\u001b[0;32m      3\u001b[0m scheduler \u001b[39m=\u001b[39m PNDMScheduler(beta_start\u001b[39m=\u001b[39m\u001b[39m0.00085\u001b[39m, beta_end\u001b[39m=\u001b[39m\u001b[39m0.012\u001b[39m, beta_schedule\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscaled_linear\u001b[39m\u001b[39m\"\u001b[39m, skip_prk_steps\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
          ]
        }
      ],
      "source": [
        "from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler\n",
        "\n",
        "scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkDYlgj4R7u5"
      },
      "source": [
        "These codes will import the 'PNDMScheduler' , 'DDIMScheduler' , and 'LMSDiscreteScheduler' classes from the diffusers library. It creates a new 'PNDMScheduler' object and sets the starting and ending values for the beta parameter. The 'PNDMScheduler' class is used to define a scheduler for the Stable Diffusion Model, which controls the diffusion process and determines how much noise is added at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Pz5edRTIOV"
      },
      "outputs": [],
      "source": [
        "import mediapy as media\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHUbA1azTJxt"
      },
      "source": [
        "These codes help us to import necessary libraries and classes for the Stable Diffusion Pipeline, including mediapy, torch, autocast, and StableDiffusionPipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "device = \"cuda\"\n",
        "remove_safety = False\n",
        "\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16, revision=\"fp16\", use_auth_token=True)\n",
        "if remove_safety:\n",
        "  pipe.safety_checker = lambda images, clip_input: (images, False)\n",
        "pipe = pipe.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAKLWeUGTiDn"
      },
      "source": [
        "The above codes sets up a Stable Diffusion Pipeline for a pretrained model with the specified model_id. The pipeline is initialized with a scheduler, a tensor data type (torch.float16), and a revision (fp16). The remove_safety variable can be set to True to remove safety checks in the pipeline. Finally, the pipeline is moved to the specified device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoTE794luOXD"
      },
      "source": [
        "Here is where you actually make images. Change the \"prompt\" to whatever you want to try and then change \"num_images\" if you want more than one image generated. You can re-run this cell without having to re-run everything before it, just FYI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUc4QJfE-uR9"
      },
      "outputs": [],
      "source": [
        "prompt = \"Generative AI\"\n",
        "num_images = 1\n",
        "\n",
        "prompts = [ prompt ] * num_images\n",
        "with autocast(\"cuda\"):\n",
        "    images = pipe(prompts, guidance_scale=7.5, num_inference_steps=50).images\n",
        "    \n",
        "media.show_images(images)\n",
        "images[0].save(\"output.jpeg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jApX41DlLHn9"
      },
      "source": [
        "This is a training sample model. we need to train it more to achieve greater results."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
